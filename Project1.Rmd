---
title: "Project 1"
output:
  html_notebook: default
  pdf_document:
    keep_tex: yes
    latex_engine: xelatex
  word_document: default
---


#Introduction

This is Project 1 for STAT 557 2018 Spring by Meridith Bartley and Fei. The aim of this project is to practice linear classification methods and QDA and study basic techniques of dimension reduction.In this project we  apply LDA, QDA, and multinomial logistic regression to soil sample data in order to classify into separate soil group (Orders). 

#Description of Data
This dataset contains soil sample data over the US downloaded from Natural Resources Conservation Service (NRCS). After removing the incomplete data records, there are around 14,000 records left, each of which includes physical and chemical properties of soil samples (sand, silt, clay, organic carbon, bulk density, CEC soil, CEC clay, base saturation, and pH) and the corresponding soil classification group (soil order). 

Boxplots for each physical and chemical property used as explanitory variables in the subsequent classification models are included below. This EDA allows for early indication of which variables may possibly be ommitted during dimention reduction. That is, what properties do not differ significantly between soil Orders.

```{r load code and clean, include=FALSE, echo = F, message = F}
# Basic clearning of our dataset 
project1data <- read.csv(file = "project1data.csv")
project1data <- project1data[,-c(1,2,4)] #remove the ID and Horizon columns which are useless,Silt is redundant information since it could be calculated from Sand and Clay. 
project1data <- project1data[sample(nrow(project1data),nrow(project1data)),] ###shuffle rows


# Create new dataset with PCA 
pca = prcomp(project1data[,-9])
print(pca$rotation)
summary.pca = summary(pca)
print(summary.pca)
project1data.new = data.frame(pca=pca$x[,1:4],Order=project1data$Order) #First 4 components explained 99.8% of the variance in the original dataset

```

```{r load required packages}
library(ggplot2)
library(dplyr)
library(magrittr)
library(MASS)
library(caret)
library(nnet) 
library(scales)
library(klaR)
library(stats)
library(grid)
library(gridExtra)


```


## Exploritory Data Analysis
```{r EDA - Mer, echo=FALSE, message = F, results = 'hide', fig.keep='all', fig.width = 8}

varlist <- names(project1data)[-9]

customPlot <- function(varName) {

project1data %>% 
group_by_("Order") %>% 
select_("Order",varName) %>% 
ggplot(aes_string("Order",varName)) + geom_boxplot() + 
   theme(axis.text.x = element_text(angle = 45, hjust = 1))

}

grid.arrange(grobs = lapply(varlist[1:4],customPlot))
grid.arrange(grobs = lapply(varlist[5:8],customPlot))


# pairs(project1data)
# cor(project1data[, -9])


```


#Analysis

##Linear Discriminant Analysis (LDA) of original dataset (without dimension reduction)

```{r}

#data partition
train_id <- caret::createDataPartition(y=project1data$Order, p=0.8,list = FALSE)
#train <- project1data[lda_train,]
#test <- project1data[-lda_train,]

```



```{r LDA with no PCA - Fei, echo=FALSE, fig.keep = 'all'}
#lda
lda.fei <- MASS::lda(Order ~., data = project1data, subset =train_id)
# plot(lda.fei)


#predict test data
test <- project1data[-train_id,]
lda.predict = predict(lda.fei, newdata=test)


# Assess the accuracy of the prediction for each soil class (Order) in test data
ct.lda <- table(test$Order, lda.predict$class)
diag(prop.table(ct.lda, 1))

# total accuracy of the prediction
sum(diag(prop.table(ct.lda)))

# Visualizing Data separation in True classification of test data
prop.lda = lda.fei$svd^2/sum(lda.fei$svd^2)

dataset = data.frame(Order = test$Order,
                     lda = lda.predict$x)

t.lda <- ggplot(dataset) + geom_point(aes(lda.LD1, lda.LD2, colour = Order), size = 1) +
  labs(x = paste("LD1 (", percent(prop.lda[1]), ")", sep=""),
       y = paste("LD2 (", percent(prop.lda[2]), ")", sep=""))


print(t.lda)


# Visualizing Data separation in Prediction Results of test data 
plot.lda = data.frame(Pclass=lda.predict$class,lda=lda.predict$x)
p.lda <- ggplot(plot.lda)+ geom_point(aes(lda.LD1,lda.LD2,colour=Pclass),size=1) +
  labs(x = paste("LD1 (", percent(prop.lda[1]), ")", sep=""),
       y = paste("LD2 (", percent(prop.lda[2]), ")", sep=""))
print(p.lda)


## MER: are LD1 and LD2 Sand + Clay? Fei: No, they are first component and second component 


```

##Linear Discriminant Analysis (LDA) of reduced dataset (with dimension reduction from PCA)

```{r LDA with PCA - Fei, echo=FALSE, fig.keep = 'all'}
#data partition
#lda_train <- caret::createDataPartition(y=project1data.new$Order, p=0.8,list = FALSE)
#train.pca <- project1data.new[lda_train,]
test.pca <- project1data.new[-train_id,]

#lda
lda.fei.pca <- MASS::lda(Order ~., data = project1data.new, subset =train_id)
# plot(lda.fei)


#predict test data
lda.predict.pca = predict(lda.fei.pca, newdata=test.pca)


# Assess the accuracy of the prediction for each soil class (Order) in test data
ct.lda.pca <- table(test.pca$Order, lda.predict.pca$class)
diag(prop.table(ct.lda.pca, 1))


# total accuracy of the prediction
sum(diag(prop.table(ct.lda.pca)))

# Visualizing Data separation in True classification of test data
prop.lda.pca = lda.fei.pca$svd^2/sum(lda.fei.pca$svd^2)

dataset.pca = data.frame(Order = test.pca$Order,
                     lda = lda.predict.pca$x)

t.lda.pca <- ggplot(dataset.pca) + geom_point(aes(lda.LD1, lda.LD2, colour = Order), size = 1) +
  labs(x = paste("LD1 (", percent(prop.lda.pca[1]), ")", sep=""),
       y = paste("LD2 (", percent(prop.lda.pca[2]), ")", sep=""))


print(t.lda.pca)


# Visualizing Data separation in Prediction Results of test data 
plot.lda.pca = data.frame(Pclass=lda.predict.pca$class,lda=lda.predict.pca$x)
p.lda.pca <- ggplot(plot.lda.pca)+ geom_point(aes(lda.LD1,lda.LD2,colour=Pclass),size=1) +
  labs(x = paste("LD1 (", percent(prop.lda.pca[1]), ")", sep=""),
       y = paste("LD2 (", percent(prop.lda.pca[2]), ")", sep=""))
print(p.lda.pca)

```



## Quadratic Discriminant Analysis (QDA) of original dataset (without dimension reduction)

```{r QDA without PCA- Fei, echo =F}

#data partition
#qda_train <- caret::createDataPartition(y=project1data$Order, p=0.8,list = FALSE)
#train <- project1data[qda_train,]
#test <- project1data[-qda_train,]

#qda
qda.fei <- MASS::qda(Order ~., data = project1data, subset =train_id)

#predict test data
qda.predict = predict(qda.fei, newdata=test)

# Assess the accuracy of the prediction for each soil class (Order) in test data
ct.qda <- table(test$Order, qda.predict$class)
diag(prop.table(ct.qda, 1))


# total accuracy of the prediction
sum(diag(prop.table(ct.qda)))


# plot results # 
# partimat(Order ~., data = project1data,metod='qda') figures are too large and took forever to show up. 

```




## Quadratic Discriminant Analysis (QDA) of reduced dataset (with dimension reduction from PCA)

```{r QDA with PCA - Fei, echo =F}

#data partition
#qda_train <- createDataPartition(y=project1data$Order, p=0.8,list = FALSE)
#train.pca <- project1data.new[qda_train,]
#test.pca <- project1data.new[-qda_train,]

#qda
qda.fei.pca <- MASS::qda(Order ~., data = project1data.new, subset =train_id)

#predict test data
qda.predict.pca = predict(qda.fei.pca, newdata=test.pca)

# Assess the accuracy of the prediction percent correct for each soil class (Order) in test data
ct.qda.pca <- table(test.pca$Order, qda.predict.pca$class)
diag(prop.table(ct.qda.pca, 1))


# total accuracy of the prediction
sum(diag(prop.table(ct.qda.pca)))

# plot results # 
partimat(Order ~., data =  project1data.new[train_id,],metod='qda') # figures are too large and took forever to show up. 

```



##Multinomial Logistic Regression

```{r Log Regression - Mer, echo = F, results = 'hide'}

#data partition
logr_train <- caret::createDataPartition(y=project1data$Order, p=0.8,list = FALSE)
train <- project1data[logr_train,]
test <- project1data[-logr_train,]

#doing logistic regression

# mylogr <- function(y, x, maxit = 100, tol = 1e-5) {
#   y <- as.numeric(y) - 1
#   X <- as.matrix(cbind(1, x))      # add the intercept term to the predictors
#   
#   # constants
#   N <- length(y)        # number of observations
#   p <- ncol(X)          # number of predictors
#   continue <- T
#   i <- 1
#   
#   betas <- matrix(0, nrow = maxit, ncol = p)
#   
#   #below is from PseudoCode - slide 21 on log reg lecture
#   while(continue && i < maxit) {
#     beta <- betas[i, ]
#     p <- exp(X %*% beta)/(1 + exp(X %*% beta))
#     W <- diag(as.vector(p * (1-p)))
#     z <- X %*% beta + solve(W) %*% (y - p)
#     betas[i+1, ] <- solve(t(X) %*% W %*% X) %*% t(X) %*% W %*% z
#     if(all(abs(betas[i + 1, ] - betas[i, ])/abs(betas[i, ]) < tol)) {
#       continue <- F
#     }
#     i <- i + 1
#   }
#   
#   return(betas[i, ])
#   
# }


#cross validation
# mylogr.cv <- function(y, x, k, maxit = 100, tol = 1e-5) {
#   
#   cvs <- rep(0, k)
#   
#   # constants
#   N <- length(y)        # number of observations
#   
#   # assign indices for which group each observation belongs to
#   kappa <- sample(rep(1:k, length = N))
#   
#   for(i in 1:k) {
#     y.tr <- y[kappa != i]     # training responses; all but ith group
#     x.tr <- x[kappa != i, ]   # training predictors; all but ith group
#     y.va <- y[kappa == i]     # validation responses; ith group
#     x.va <- x[kappa == i, ]   # validation predictors; ith group
#     
#     beta <- mylogr(y.tr, x.tr, maxit, tol)
#     
#     X.va <- as.matrix(cbind(1, x.va))
#     
#     prediction <- rep(NA, length(y.va))
#     for(j in 1:length(prediction)) {
#       prediction[j] <- round(1/(1+exp(-t(beta) %*% X.va[j, ])))
#     }
#     cvs[i] <- sum((prediction - (as.numeric(y.va)-1))^2)
#   }
#   
#   return(sum(cvs)/N)
#   
# }

# system.time(cv.err.logr <- mylogr.cv(data$class, data[ ,-10], 10))
  
  
#below doesn't seem to work - W becomes singular
# logr.mer <- mylogr(y = train[1:100, 9] , x = train[1:100,-9])


logr.mer <- nnet::multinom(Order ~ ., data = project1data, subset = logr_train)
summary(logr.mer)

logr.predict <- predict(logr.mer, newdata = test)
  
ct.logr <- table(test$Order, logr.predict)


 
PCA <- princomp(project1data[, -9] ,cor="False")
summary(PCA)  
biplot(PCA)

#post-PCA Only retain first three variables
# PCA.data <- project1data[, -c(5:8)]
# PCA.test <- test[, -c(5:8)] 


logr.PCA <- nnet::multinom(Order ~ ., data = project1data.new, subset = logr_train)
summary(logr.PCA)

logr.PCA.predict <- predict(logr.PCA, newdata = test.pca)
  
ct.logr.PCA <- table(test.pca$Order, logr.PCA.predict)


#mult log reg
correct.logr.PCA <- diag(prop.table(ct.logr.PCA, 1))
# total percent correct
tot.correct.logr.PCA <- sum(diag(prop.table(ct.logr.PCA)))

round(correct.logr.PCA, 2)
round(tot.correct.logr.PCA, 2)
```



#Results

The results from these three approaches show that...


In order to compare the reults it is important to recall the diffences between these three classification approaches. The difference between LDA and logistic regression is that linear coefficients are estimated differently. MLE for logistic models and estimated mean and variance based on Gaussian assumptions for the LDA. LDA makes more restrictive Gaussian assumptions and therefore often expected to work better than logistic models IF they are met. QDA serves as a compromise between non-parametric methods (not explored in this project) and the linear LDA and logistic regression approaches. Since QDA assumes a quadratic decision boundary, it can accurately model a wider range of problems than can the linear methods. QDA can perform better in the presence of a limited number of training observations because it does make some assumptions about the form of the decision boundary.


```{r Model Comparison - Mer, echo = F, warning = F, message = F, results = F}
#lda
correct.lda <- diag(prop.table(ct.lda, 1))
# total percent correct
totcorrect.lda <- sum(diag(prop.table(ct.lda)))

#qda
correct.qda <- diag(prop.table(ct.qda, 1))
# total percent correct
totcorrect.qda <- sum(diag(prop.table(ct.qda)))

#mult log reg
correct.logr <- diag(prop.table(ct.logr, 1))
# total percent correct
tot.correct.logr <- sum(diag(prop.table(ct.logr)))

#output table

model_comparison <- bind_rows(correct.lda, correct.qda, correct.logr)


model_comparison <- model_comparison %>%
                    mutate(Overall = c(totcorrect.lda, 0.58, tot.correct.logr)) %>% 
  set_rownames(c("LDA", "QDA", "Mult Log Reg"))

knitr::kable(round(model_comparison, digits = 2))

```

#Contributions
  